wandb:
  project: Bart-xsum
  exp_num: 1
  tags: [bart]
model:
  pretrained_model_name : 'facebook/bart-base'
  epoch : 2
  seed : 40
  accumulate_grad_batches: 4
  data_module: 
    batch_size : 2
    document_max_length: 1024
    summary_max_length: 400
  optimizer:
    name : "RAdam"
    lr : 1e-5
  early_stopping :
    monitor: "val/loss"
    patience: 3
    mode : "min"
    min_delta: 0.02
  checkpoint :
    monitor: "val/loss"
    mode: "min"
    filename: "2" #ここよくわからん
    verbose: True
  data : 
    train_rate: 0.9
sweep:
  method: "random"
  metric:
    goal: "minimize"
    name: "val/loss"
  parameters:
    data_module:
      parameters:
        batch_size:
          values: [1, 2, 3, 4]
          text_max_length: 1024
          summary_max_length: 400 #データセットの要約の最大が399語だった
    optimizer:
      parameters:
        name:
          values: ["AdamW", "RAdam"]
        lr:
          values: [1e-5, 5e-5, 9e-5, 1e-6]